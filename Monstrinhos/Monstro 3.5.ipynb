{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Monstrinhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Forma, função e ativação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo desta atividade é implementar 3 novas funções de ativação da rede neural feita em Python\n",
    "puro nos vídeos da disciplina, descrevendo brevemente sobre estas funções de ativação e suas diferenças com relação à função de ativação sigmoidal. Além disso, mostrou-se alguns exemplos de que o código funciona rodando alguns testes simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função ReLU (Unidade Linear Retificada):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função Tanh (Tangente Hiperbólica):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função Softmax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvimento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo as classes principais da rede neural, contendo cada neurônio e camada. Essas classes foram baseadas no material de aula do Daniel Cassar [] e do vídeo do Andrej Karpathy [], adaptando para as funções de ativação escolhidas. Definindo as 3 funções na classe Valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Valor:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data # grad_filho * derivada filho em relação a mãe\n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a operação: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a operação: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a operação: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "    \n",
    "    # Funções de ativação\n",
    "    def sig(self):\n",
    "        \"\"\"Função Sigmoide. Realiza a operação: exp(self) / (exp(self) + 1)\"\"\"\n",
    "        return self.exp() / (self.exp() + 1)\n",
    "\n",
    "    def relu(self):\n",
    "        \"\"\"Função ReLU. Realiza a operação: max(0, self), \"\"\"\n",
    "\n",
    "        progenitor = (self, )\n",
    "        data = 0 if self.data < 0 else self.data\n",
    "        operador_mae = \"ReLU\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_relu():\n",
    "            self.grad += (resultado.data > 0) * resultado.grad \n",
    "        \n",
    "        resultado.propagar = propagar_relu\n",
    "        \n",
    "        return resultado\n",
    "\n",
    "    def tanh(self):\n",
    "        \"\"\"Função tangente hiperbólica. Realiza a operação: exp(self) - exp(-self) / exp(self) + exp(-self)\"\"\"\n",
    "\n",
    "        progenitor = (self, )\n",
    "        data = \n",
    "        operador_mae = \"Tanh\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_tanh():\n",
    "            self.grad += (resultado.data > 0) * resultado.grad \n",
    "        \n",
    "        resultado.propagar = propagar_tanh\n",
    "        \n",
    "        return resultado\n",
    "\n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n",
    "        out = Value(t, (self, ), 'tanh')\n",
    "    \n",
    "        def _backward():\n",
    "            self.grad += (1 - t**2) * out.grad\n",
    "        out._backward = _backward\n",
    "        \n",
    "        return out\n",
    "\n",
    "    #def softmax(self):\n",
    "        #\"\"\"Função Softmax. Realiza a operação: exp(self) / (exp(self) + 1)\"\"\"\n",
    "        #return self.exp() / (self.exp() + 1)\n",
    "\n",
    "    \n",
    "    def propagar(self):\n",
    "        pass\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax\n",
    "# Calculate exp(x) for each element\n",
    "    #exp_x = np.exp(shifted_x)\n",
    "    \n",
    "    # Calculate the sum of exp(x) for normalization\n",
    "    #sum_exp_x = np.sum(exp_x, axis=-1, keepdims=True)\n",
    "    \n",
    "    # Normalize to get probabilities\n",
    "    #probabilities = exp_x / sum_exp_x\n",
    "    \n",
    "    #return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanh: f(x) = (e^x - e^-x) / (e^x + e^-x)\n",
    "\n",
    "Relu: f(x) = max(0, x)\n",
    "\n",
    "Soft: f(xi) = e^xi / Σj e^xj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na classe Neuronio é possível escolher a função de ativação desejada como argumento para criar um neurônio, aplicando ao dado de saída:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuronio:\n",
    "    def __init__(self, num_dados_entrada, fc = 'Sigmoide'):\n",
    "        \"\"\"Modo de representar cada neurônio da rede neural\n",
    "        \n",
    "        Args:\n",
    "            num_dados_entrada: inteiro, indica o número de dados de entrada do neurônio\n",
    "            fc: string, indica a função de ativação aplicada ao neurônio, podendo ser:\n",
    "                - Sigmoide (padrão)\n",
    "                - ReLU\n",
    "                - Tanh\n",
    "                - Softmax\n",
    "\n",
    "        Return\n",
    "            Ao ser chamada retorna o valor de saída do neurônio (tipo Valor) após transformar \n",
    "            os dados de entrada com o peso, viés e função de ativação\n",
    "        \"\"\"\n",
    "        \n",
    "        self.vies = Valor(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor(random.uniform(-1, 1)))\n",
    "\n",
    "        self.funcao = fc\n",
    "                    \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        assert len(x) == len(self.pesos)\n",
    "        \n",
    "        soma = 0\n",
    "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
    "            soma += info_entrada * peso_interno\n",
    "            \n",
    "        soma += self.vies  \n",
    "\n",
    "        if self.funcao == \"Sigmoide\":\n",
    "            dado_de_saida = soma.sig() \n",
    "        elif self.funcao == \"ReLU\":\n",
    "            dado_de_saida = soma.relu() \n",
    "        elif self.funcao == \"Tanh\":\n",
    "            dado_de_saida = soma.tanh() \n",
    "        elif self.funcao == \"Softmax\":\n",
    "            # usar um if pra certificar que é a camada de saída (aplicar só 1 vez)\n",
    "            dado_de_saida = soma.softmax()  \n",
    "\n",
    "        return dado_de_saida       \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As outras classes mantém-se constantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camada:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada):\n",
    "        neuronios = []\n",
    "        \n",
    "        for _ in range(num_neuronios):\n",
    "            neuronio = Neuronio(num_dados_entrada)\n",
    "            neuronios.append(neuronio)\n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
    "        \n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada(num_neuronios_por_camada[i], percurso[i])\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] \n",
    "\n",
    "[2] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
