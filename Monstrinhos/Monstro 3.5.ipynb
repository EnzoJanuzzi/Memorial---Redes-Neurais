{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Monstrinhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Forma, função e ativação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo desta atividade é implementar 3 novas funções de ativação da rede neural feita em Python\n",
    "puro nos vídeos da disciplina [1], descrevendo brevemente sobre estas funções de ativação e suas diferenças com relação à função de ativação sigmoidal. Além disso, mostrou-se alguns exemplos de que o código funciona rodando alguns testes simples. A fundamentação teórica sobre as funções foi baseada em 2 sites, que explicam e mostram gráficos ilustrativos [2,3]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função ReLU (Unidade Linear Retificada):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função transforma os dados de entrada dos neurônios zerando os valores negativos e retornando a própria entrada para valores positivos. Matematicamente:\n",
    "\n",
    "$$ReLU(x) = max(0, x) $$\n",
    "\n",
    "Assim, para entradas maiores que 0, o ReLU atua como uma função linear com um gradiente de 1, não alterando a escala de entradas positivas. Isso é computacionalmente barato, porque envolve um limiar simples em zero, permitindo que as redes sejam dimensionadas para muitas camadas sem um aumento significativo na carga computacional, em comparação com funções mais complexas, como a sigmoide.\n",
    "\n",
    "No entanto, uma desvantagem desse modelo é que ele naturalmente leva a ativações esparsas, ativando apenas um subconjunto de neurônios, o que pode criar \"neurônios mortos\" no treinamento, com a informação de um neurônio não sendo passada adiante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função Tanh (Tangente Hiperbólica):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função de tangente hiperbólica converte os valores em um intervalo de -1 a +1, podendo ser definida de algumas formas [4]. Para esse problema, o formato da função escolhida foi:\n",
    "\n",
    "$$tanh(x) = \\frac{e^{2x} - 1}{e^{2x} + 1}$$\n",
    "\n",
    "Ao contrário da função sigmoide, que tem um intervalo de 0 a 1, a tanh é centrada em zero, lidando melhor com valores negativos, além de ter aprendizado e convergência mais rápidos durante o treinamento.  \n",
    "\n",
    "Apesar dessas vantagens, a função tanh ainda pode apresentar o problema do gradiente de desaparecimento, quando os gradientes ficam muito próximos de zero, o que afeta a atualização dos parâmetros do modelo. Isso pode desacelerar o processo de treinamento, resultando em convergências ruins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função Swish:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função de ativação foi desenvolvida por pesquisadores do Google, buscando resolver problemas associados à função ReLU. Matematicamente:\n",
    "\n",
    "$$swish(x) = x * sigmoide(x)$$\n",
    "\n",
    "Ela é uma função suave que não muda de direção abruptamente para valores próximos de 0, curvando-se levemente e voltando a subir para valores positivos. Isso melhora a expressão dos dados de entrada e dos pesos a serem atualizados, ao contrário da ReLU, que implica a perda de parte da informação passada pela rede neural. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvimento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas necessárias [5,6]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo as classes principais da rede neural, contendo cada neurônio e camada. Essas classes foram baseadas no material de aula do Daniel Cassar [1] e do vídeo do Andrej Karpathy [7], adaptando para as funções de ativação escolhidas. Definindo as 3 funções na classe Valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Valor:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data # grad_filho * derivada filho em relação a mãe\n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a operação: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a operação: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a operação: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "    \n",
    "    # Funções de ativação\n",
    "    def sig(self):\n",
    "        \"\"\"Função Sigmoide. Realiza a operação: exp(self) / (exp(self) + 1)\"\"\"\n",
    "        return self.exp() / (self.exp() + 1)\n",
    "\n",
    "    def relu(self):\n",
    "        \"\"\"Função ReLU. Realiza a operação: max(0, self), \"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = max(0, self.data)\n",
    "        operador_mae = \"relu\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_relu():\n",
    "            if data > 0:\n",
    "                self.grad += resultado.grad\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        resultado.propagar = propagar_relu\n",
    "        \n",
    "        return resultado\n",
    "        \n",
    "    def tanh(self):\n",
    "        \"\"\"Função tangente hiperbólica. Realiza a operação: (exp(2 * self) - 1) / (exp(2 * self) + 1)\"\"\"\n",
    "\n",
    "        x = 2 * self\n",
    "        return (x.exp() - 1) / (x.exp() + 1)\n",
    "   \n",
    "    def swish(self):\n",
    "        \"\"\"Função Swish. Realiza a operação: self * \"\"\"\n",
    "        return self * self.sig()\n",
    "    \n",
    "    def propagar(self):\n",
    "        pass\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na classe Neuronio é possível escolher a função de ativação desejada como argumento para criar um neurônio, aplicando ao dado de saída:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuronio:\n",
    "    def __init__(self, num_dados_entrada, fc = 'Sigmoide'):\n",
    "        \"\"\"Modo de representar cada neurônio da rede neural\n",
    "        \n",
    "        Args:\n",
    "            num_dados_entrada: inteiro, indica o número de dados de entrada do neurônio\n",
    "            fc: string, indica a função de ativação aplicada ao neurônio, podendo ser:\n",
    "                - Sigmoide (padrão)\n",
    "                - ReLU\n",
    "                - Tanh\n",
    "                - Softmax\n",
    "\n",
    "        Return\n",
    "            Ao ser chamada retorna o valor de saída do neurônio (tipo Valor) após transformar \n",
    "            os dados de entrada com o peso, viés e função de ativação\n",
    "        \"\"\"\n",
    "        \n",
    "        self.vies = Valor(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor(random.uniform(-1, 1)))\n",
    "                    \n",
    "    def __call__(self, x, fc):\n",
    "        \n",
    "        assert len(x) == len(self.pesos)\n",
    "        \n",
    "        soma = 0\n",
    "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
    "            soma += info_entrada * peso_interno\n",
    "            \n",
    "        soma += self.vies  \n",
    "\n",
    "        if fc == \"Sigmoide\":\n",
    "            dado_de_saida = soma.sig() \n",
    "        elif fc == \"ReLU\":\n",
    "            dado_de_saida = soma.relu() \n",
    "        elif fc == \"Tanh\":\n",
    "            dado_de_saida = soma.tanh() \n",
    "        elif fc == \"Swish\":\n",
    "            dado_de_saida = soma.swish()  \n",
    "\n",
    "        return dado_de_saida       \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As outras classes mantém-se constantes, definindo como construir as camadas e a rede neural completa, apenas incluindo a função de ativação desejada como argumento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camada:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada, fc):\n",
    "        neuronios = []\n",
    "        \n",
    "        for _ in range(num_neuronios):\n",
    "            neuronio = Neuronio(num_dados_entrada, fc)\n",
    "            neuronios.append(neuronio)\n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x, fc):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x, fc)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada, fc):\n",
    "        self.funcao = fc\n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada(num_neuronios_por_camada[i], percurso[i], fc)\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x, fc):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x, fc)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo as etapas de treinamento da rede neural, em que fazemos a previsão do modelo, calculamos o erro, zeramos os gradientes, fazemos o backpropagation e atualizamos os parâmetros, dependendo da rede neural escolhida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinamento(NUM_EPOCAS, TAXA_DE_APRENDIZADO, rede_neural, x, y_true):    \n",
    "    for epoca in range(NUM_EPOCAS):\n",
    "        # forward pass\n",
    "        y_pred = []\n",
    "        for exemplo in x:\n",
    "            previsao = rede_neural(exemplo, rede_neural.funcao)\n",
    "            y_pred.append(previsao)\n",
    "\n",
    "        # loss\n",
    "            erros = []\n",
    "            for yt, yp in zip(y_true, y_pred):\n",
    "                residuo = yp - yt\n",
    "                erro_quadratico = residuo ** 2\n",
    "                erros.append(erro_quadratico)        \n",
    "            loss = sum(erros)\n",
    "\n",
    "        # zero grad\n",
    "        for p in rede_neural.parametros():\n",
    "            p.grad = 0\n",
    "\n",
    "        # backpropagation\n",
    "        loss.propagar_tudo()\n",
    "\n",
    "        # atualiza parâmetros\n",
    "        for p in rede_neural.parametros():\n",
    "            p.data = p.data - p.grad * TAXA_DE_APRENDIZADO\n",
    "\n",
    "        # mostra resultado (opcional)\n",
    "        print(f'Época: {epoca}, Perda: {loss.data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando a arquitetura de rede neural variando a função de ativação e definindo os hiperparâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DADOS_DE_ENTRADA = 3  \n",
    "NUM_DADOS_DE_SAIDA = 1    \n",
    "CAMADAS_OCULTAS = [3, 2]\n",
    "FUNCAO_ATIVACAO = ['Tanh', 'ReLU', 'Swish']  \n",
    "\n",
    "arquitetura_da_rede = CAMADAS_OCULTAS + [NUM_DADOS_DE_SAIDA]\n",
    "\n",
    "nn_tanh = MLP(NUM_DADOS_DE_ENTRADA, arquitetura_da_rede, FUNCAO_ATIVACAO[0])\n",
    "nn_relu = MLP(NUM_DADOS_DE_ENTRADA, arquitetura_da_rede, FUNCAO_ATIVACAO[1])\n",
    "nn_swish = MLP(NUM_DADOS_DE_ENTRADA, arquitetura_da_rede, FUNCAO_ATIVACAO[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um exemplo simples para testar a performance dos modelos, com 3 dados de entrada para cada exemplo e 1 dado de saída:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]\n",
    "\n",
    "y_true = [1, 0, 0.2, 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando a rede neural com a função *tanh*. Definiu-se um número de épocas como 100 e uma taxa de aprendizado de 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época: 0, Perda: 1.7830194450528556\n",
      "Época: 1, Perda: 1.1638989983369203\n",
      "Época: 2, Perda: 0.7985418517673731\n",
      "Época: 3, Perda: 0.5957506923419789\n",
      "Época: 4, Perda: 0.4811783443478552\n",
      "Época: 5, Perda: 0.41308113281525166\n",
      "Época: 6, Perda: 0.3700609320626339\n",
      "Época: 7, Perda: 0.3411010848148787\n",
      "Época: 8, Perda: 0.32033947398628204\n",
      "Época: 9, Perda: 0.30453561783178434\n",
      "Época: 10, Perda: 0.2918335293646483\n",
      "Época: 11, Perda: 0.28113703629960757\n",
      "Época: 12, Perda: 0.271781825725135\n",
      "Época: 13, Perda: 0.26335662566049656\n",
      "Época: 14, Perda: 0.25560228838155186\n",
      "Época: 15, Perda: 0.24835308260682756\n",
      "Época: 16, Perda: 0.2415016318525439\n",
      "Época: 17, Perda: 0.23497750118702274\n",
      "Época: 18, Perda: 0.22873387208266155\n",
      "Época: 19, Perda: 0.2227391219393957\n",
      "Época: 20, Perda: 0.21697143762786952\n",
      "Época: 21, Perda: 0.2114153380374317\n",
      "Época: 22, Perda: 0.2060594150277543\n",
      "Época: 23, Perda: 0.20089486116080968\n",
      "Época: 24, Perda: 0.1959145102086182\n",
      "Época: 25, Perda: 0.19111221415423443\n",
      "Época: 26, Perda: 0.18648244199427563\n",
      "Época: 27, Perda: 0.18202002503502276\n",
      "Época: 28, Perda: 0.17771999887581122\n",
      "Época: 29, Perda: 0.17357750896439475\n",
      "Época: 30, Perda: 0.16958775763185466\n",
      "Época: 31, Perda: 0.1657459778476476\n",
      "Época: 32, Perda: 0.16204742384151455\n",
      "Época: 33, Perda: 0.15848737203489277\n",
      "Época: 34, Perda: 0.15506112794428928\n",
      "Época: 35, Perda: 0.15176403621550144\n",
      "Época: 36, Perda: 0.14859149195558785\n",
      "Época: 37, Perda: 0.1455389522067055\n",
      "Época: 38, Perda: 0.1426019468587139\n",
      "Época: 39, Perda: 0.13977608859788104\n",
      "Época: 40, Perda: 0.137057081686185\n",
      "Época: 41, Perda: 0.13444072949297983\n",
      "Época: 42, Perda: 0.13192294078102554\n",
      "Época: 43, Perda: 0.12949973479761706\n",
      "Época: 44, Perda: 0.12716724524938663\n",
      "Época: 45, Perda: 0.12492172325351651\n",
      "Época: 46, Perda: 0.12275953936343287\n",
      "Época: 47, Perda: 0.12067718476686817\n",
      "Época: 48, Perda: 0.11867127175063502\n",
      "Época: 49, Perda: 0.11673853352101617\n",
      "Época: 50, Perda: 0.11487582346227501\n",
      "Época: 51, Perda: 0.1130801139090267\n",
      "Época: 52, Perda: 0.11134849450146121\n",
      "Época: 53, Perda: 0.10967817018589056\n",
      "Época: 54, Perda: 0.1080664589169383\n",
      "Época: 55, Perda: 0.10651078911194055\n",
      "Época: 56, Perda: 0.10500869690283335\n",
      "Época: 57, Perda: 0.10355782322592678\n",
      "Época: 58, Perda: 0.10215591078551846\n",
      "Época: 59, Perda: 0.1008008009232429\n",
      "Época: 60, Perda: 0.09949043042136337\n",
      "Época: 61, Perda: 0.09822282826485765\n",
      "Época: 62, Perda: 0.09699611238411016\n",
      "Época: 63, Perda: 0.09580848639726376\n",
      "Época: 64, Perda: 0.09465823636879223\n",
      "Época: 65, Perda: 0.09354372759859068\n",
      "Época: 66, Perda: 0.09246340145385143\n",
      "Época: 67, Perda: 0.09141577225415003\n",
      "Época: 68, Perda: 0.09039942421851466\n",
      "Época: 69, Perda: 0.08941300848176781\n",
      "Época: 70, Perda: 0.08845524018610033\n",
      "Época: 71, Perda: 0.0875248956526476\n",
      "Época: 72, Perda: 0.08662080963677991\n",
      "Época: 73, Perda: 0.08574187266988267\n",
      "Época: 74, Perda: 0.08488702848956842\n",
      "Época: 75, Perda: 0.0840552715595293\n",
      "Época: 76, Perda: 0.08324564467960459\n",
      "Época: 77, Perda: 0.0824572366860705\n",
      "Época: 78, Perda: 0.0816891802416797\n",
      "Época: 79, Perda: 0.08094064971456238\n",
      "Época: 80, Perda: 0.08021085914474009\n",
      "Época: 81, Perda: 0.07949906029670714\n",
      "Época: 82, Perda: 0.0788045407962818\n",
      "Época: 83, Perda: 0.0781266223497217\n",
      "Época: 84, Perda: 0.07746465904293008\n",
      "Época: 85, Perda: 0.07681803571844925\n",
      "Época: 86, Perda: 0.07618616642783392\n",
      "Época: 87, Perda: 0.07556849295692578\n",
      "Época: 88, Perda: 0.0749644834214975\n",
      "Época: 89, Perda: 0.07437363093071078\n",
      "Época: 90, Perda: 0.07379545231582017\n",
      "Época: 91, Perda: 0.07322948692155931\n",
      "Época: 92, Perda: 0.07267529545766943\n",
      "Época: 93, Perda: 0.07213245890805807\n",
      "Época: 94, Perda: 0.0716005774951189\n",
      "Época: 95, Perda: 0.07107926969679064\n",
      "Época: 96, Perda: 0.07056817131399325\n",
      "Época: 97, Perda: 0.07006693458613486\n",
      "Época: 98, Perda: 0.06957522735245587\n",
      "Época: 99, Perda: 0.06909273225704045\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 100\n",
    "TAXA_DE_APRENDIZADO = 0.01\n",
    "\n",
    "treino_tanh = treinamento(NUM_EPOCAS, TAXA_DE_APRENDIZADO, nn_tanh, x, y_true)\n",
    "treino_tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treino foi bem-sucedido, diminuindo a perda a cada época"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetindo o procedimento para o modelo com função ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época: 0, Perda: 1.29\n",
      "Época: 1, Perda: 1.29\n",
      "Época: 2, Perda: 1.29\n",
      "Época: 3, Perda: 1.29\n",
      "Época: 4, Perda: 1.29\n",
      "Época: 5, Perda: 1.29\n",
      "Época: 6, Perda: 1.29\n",
      "Época: 7, Perda: 1.29\n",
      "Época: 8, Perda: 1.29\n",
      "Época: 9, Perda: 1.29\n",
      "Época: 10, Perda: 1.29\n",
      "Época: 11, Perda: 1.29\n",
      "Época: 12, Perda: 1.29\n",
      "Época: 13, Perda: 1.29\n",
      "Época: 14, Perda: 1.29\n",
      "Época: 15, Perda: 1.29\n",
      "Época: 16, Perda: 1.29\n",
      "Época: 17, Perda: 1.29\n",
      "Época: 18, Perda: 1.29\n",
      "Época: 19, Perda: 1.29\n",
      "Época: 20, Perda: 1.29\n",
      "Época: 21, Perda: 1.29\n",
      "Época: 22, Perda: 1.29\n",
      "Época: 23, Perda: 1.29\n",
      "Época: 24, Perda: 1.29\n",
      "Época: 25, Perda: 1.29\n",
      "Época: 26, Perda: 1.29\n",
      "Época: 27, Perda: 1.29\n",
      "Época: 28, Perda: 1.29\n",
      "Época: 29, Perda: 1.29\n",
      "Época: 30, Perda: 1.29\n",
      "Época: 31, Perda: 1.29\n",
      "Época: 32, Perda: 1.29\n",
      "Época: 33, Perda: 1.29\n",
      "Época: 34, Perda: 1.29\n",
      "Época: 35, Perda: 1.29\n",
      "Época: 36, Perda: 1.29\n",
      "Época: 37, Perda: 1.29\n",
      "Época: 38, Perda: 1.29\n",
      "Época: 39, Perda: 1.29\n",
      "Época: 40, Perda: 1.29\n",
      "Época: 41, Perda: 1.29\n",
      "Época: 42, Perda: 1.29\n",
      "Época: 43, Perda: 1.29\n",
      "Época: 44, Perda: 1.29\n",
      "Época: 45, Perda: 1.29\n",
      "Época: 46, Perda: 1.29\n",
      "Época: 47, Perda: 1.29\n",
      "Época: 48, Perda: 1.29\n",
      "Época: 49, Perda: 1.29\n",
      "Época: 50, Perda: 1.29\n",
      "Época: 51, Perda: 1.29\n",
      "Época: 52, Perda: 1.29\n",
      "Época: 53, Perda: 1.29\n",
      "Época: 54, Perda: 1.29\n",
      "Época: 55, Perda: 1.29\n",
      "Época: 56, Perda: 1.29\n",
      "Época: 57, Perda: 1.29\n",
      "Época: 58, Perda: 1.29\n",
      "Época: 59, Perda: 1.29\n",
      "Época: 60, Perda: 1.29\n",
      "Época: 61, Perda: 1.29\n",
      "Época: 62, Perda: 1.29\n",
      "Época: 63, Perda: 1.29\n",
      "Época: 64, Perda: 1.29\n",
      "Época: 65, Perda: 1.29\n",
      "Época: 66, Perda: 1.29\n",
      "Época: 67, Perda: 1.29\n",
      "Época: 68, Perda: 1.29\n",
      "Época: 69, Perda: 1.29\n",
      "Época: 70, Perda: 1.29\n",
      "Época: 71, Perda: 1.29\n",
      "Época: 72, Perda: 1.29\n",
      "Época: 73, Perda: 1.29\n",
      "Época: 74, Perda: 1.29\n",
      "Época: 75, Perda: 1.29\n",
      "Época: 76, Perda: 1.29\n",
      "Época: 77, Perda: 1.29\n",
      "Época: 78, Perda: 1.29\n",
      "Época: 79, Perda: 1.29\n",
      "Época: 80, Perda: 1.29\n",
      "Época: 81, Perda: 1.29\n",
      "Época: 82, Perda: 1.29\n",
      "Época: 83, Perda: 1.29\n",
      "Época: 84, Perda: 1.29\n",
      "Época: 85, Perda: 1.29\n",
      "Época: 86, Perda: 1.29\n",
      "Época: 87, Perda: 1.29\n",
      "Época: 88, Perda: 1.29\n",
      "Época: 89, Perda: 1.29\n",
      "Época: 90, Perda: 1.29\n",
      "Época: 91, Perda: 1.29\n",
      "Época: 92, Perda: 1.29\n",
      "Época: 93, Perda: 1.29\n",
      "Época: 94, Perda: 1.29\n",
      "Época: 95, Perda: 1.29\n",
      "Época: 96, Perda: 1.29\n",
      "Época: 97, Perda: 1.29\n",
      "Época: 98, Perda: 1.29\n",
      "Época: 99, Perda: 1.29\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 100\n",
    "TAXA_DE_APRENDIZADO = 0.5\n",
    "\n",
    "treino_relu = treinamento(NUM_EPOCAS, TAXA_DE_APRENDIZADO, nn_relu, x, y_true)\n",
    "treino_relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a perda se mantém contante ao longo das épocas, indicando que o modelo não se ajusta tão bem aos dados na atualização dos parâmetros. Isso indica que aplicar a função ReLU em todos os neurônios (inclusive na camada de saída) não é uma forma razoável de treinar a rede neural, necessitando de ajustes pelo menos no output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, fazendo para o modelo com função Swish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época: 0, Perda: 2.381661078280655\n",
      "Época: 1, Perda: 1.92245404990186\n",
      "Época: 2, Perda: 1.6942557175401296\n",
      "Época: 3, Perda: 1.6439927709223596\n",
      "Época: 4, Perda: 1.483701122936058\n",
      "Época: 5, Perda: 1.3212241280546018\n",
      "Época: 6, Perda: 1.306223539197802\n",
      "Época: 7, Perda: 1.3008729677760156\n",
      "Época: 8, Perda: 1.2981082486685653\n",
      "Época: 9, Perda: 1.29642425326925\n",
      "Época: 10, Perda: 1.295294764552123\n",
      "Época: 11, Perda: 1.2944870633541503\n",
      "Época: 12, Perda: 1.2938823171516112\n",
      "Época: 13, Perda: 1.2934135588421944\n",
      "Época: 14, Perda: 1.2930402163424055\n",
      "Época: 15, Perda: 1.2927363024570275\n",
      "Época: 16, Perda: 1.292484419276088\n",
      "Época: 17, Perda: 1.2922724916729504\n",
      "Época: 18, Perda: 1.2920918836942779\n",
      "Época: 19, Perda: 1.2919362604105942\n",
      "Época: 20, Perda: 1.2918008726994943\n",
      "Época: 21, Perda: 1.2916820925340622\n",
      "Época: 22, Perda: 1.2915771022078524\n",
      "Época: 23, Perda: 1.2914836812144168\n",
      "Época: 24, Perda: 1.2914000568256894\n",
      "Época: 25, Perda: 1.2913247972533002\n",
      "Época: 26, Perda: 1.2912567339052061\n",
      "Época: 27, Perda: 1.291194903914497\n",
      "Época: 28, Perda: 1.2911385070437975\n",
      "Época: 29, Perda: 1.2910868729477176\n",
      "Época: 30, Perda: 1.2910394360076969\n",
      "Época: 31, Perda: 1.2909957157766982\n",
      "Época: 32, Perda: 1.2909553016307613\n",
      "Época: 33, Perda: 1.2909178406108783\n",
      "Época: 34, Perda: 1.2908830277095191\n",
      "Época: 35, Perda: 1.2908505980484846\n",
      "Época: 36, Perda: 1.290820320533165\n",
      "Época: 37, Perda: 1.2907919926689193\n",
      "Época: 38, Perda: 1.2907654362993624\n",
      "Época: 39, Perda: 1.2907404940813318\n",
      "Época: 40, Perda: 1.2907170265525743\n",
      "Época: 41, Perda: 1.2906949096793983\n",
      "Época: 42, Perda: 1.2906740327953465\n",
      "Época: 43, Perda: 1.2906542968602621\n",
      "Época: 44, Perda: 1.2906356129832954\n",
      "Época: 45, Perda: 1.2906179011644618\n",
      "Época: 46, Perda: 1.2906010892180526\n",
      "Época: 47, Perda: 1.2905851118480576\n",
      "Época: 48, Perda: 1.2905699098512156\n",
      "Época: 49, Perda: 1.2905554294276649\n",
      "Época: 50, Perda: 1.2905416215826782\n",
      "Época: 51, Perda: 1.290528441605787\n",
      "Época: 52, Perda: 1.2905158486158994\n",
      "Época: 53, Perda: 1.290503805162895\n",
      "Época: 54, Perda: 1.2904922768777058\n",
      "Época: 55, Perda: 1.2904812321641619\n",
      "Época: 56, Perda: 1.2904706419269156\n",
      "Época: 57, Perda: 1.2904604793306302\n",
      "Época: 58, Perda: 1.2904507195863344\n",
      "Época: 59, Perda: 1.290441339761446\n",
      "Época: 60, Perda: 1.2904323186104647\n",
      "Época: 61, Perda: 1.2904236364237796\n",
      "Época: 62, Perda: 1.290415274892366\n",
      "Época: 63, Perda: 1.2904072169864653\n",
      "Época: 64, Perda: 1.2903994468466036\n",
      "Época: 65, Perda: 1.2903919496855059\n",
      "Época: 66, Perda: 1.2903847116996676\n",
      "Época: 67, Perda: 1.290377719989486\n",
      "Época: 68, Perda: 1.2903709624870179\n",
      "Época: 69, Perda: 1.2903644278905155\n",
      "Época: 70, Perda: 1.2903581056050242\n",
      "Época: 71, Perda: 1.2903519856883905\n",
      "Época: 72, Perda: 1.2903460588021247\n",
      "Época: 73, Perda: 1.290340316166611\n",
      "Época: 74, Perda: 1.290334749520225\n",
      "Época: 75, Perda: 1.2903293510819784\n",
      "Época: 76, Perda: 1.2903241135173242\n",
      "Época: 77, Perda: 1.2903190299068328\n",
      "Época: 78, Perda: 1.2903140937174515\n",
      "Época: 79, Perda: 1.2903092987761107\n",
      "Época: 80, Perda: 1.2903046392454502\n",
      "Época: 81, Perda: 1.290300109601477\n",
      "Época: 82, Perda: 1.2902957046129702\n",
      "Época: 83, Perda: 1.2902914193224877\n",
      "Época: 84, Perda: 1.2902872490288186\n",
      "Época: 85, Perda: 1.2902831892707638\n",
      "Época: 86, Perda: 1.2902792358121293\n",
      "Época: 87, Perda: 1.2902753846278217\n",
      "Época: 88, Perda: 1.290271631890961\n",
      "Época: 89, Perda: 1.290267973960916\n",
      "Época: 90, Perda: 1.2902644073722005\n",
      "Época: 91, Perda: 1.2902609288241385\n",
      "Época: 92, Perda: 1.2902575351712597\n",
      "Época: 93, Perda: 1.290254223414351\n",
      "Época: 94, Perda: 1.290250990692115\n",
      "Época: 95, Perda: 1.2902478342733943\n",
      "Época: 96, Perda: 1.2902447515499094\n",
      "Época: 97, Perda: 1.2902417400294794\n",
      "Época: 98, Perda: 1.2902387973296787\n",
      "Época: 99, Perda: 1.2902359211719094\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 100\n",
    "TAXA_DE_APRENDIZADO = 0.5\n",
    "\n",
    "treino_swish = treinamento(NUM_EPOCAS, TAXA_DE_APRENDIZADO, nn_swish, x, y_true)\n",
    "treino_swish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo se ajustou relativamente bem aos dados, diminuindo a perda a cada época. Note, no entanto, que no meu caso a perda subiu na época 5 e voltou a diminuir, mas com uma taxa menor para as épocas finais. Isso sugere que o modelo pode ter subajustado parte dos dados, mas conseguiu ser treinado posteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível estimar a performance dos modelos comparando sua perda, mas seria necessário fixar os parâmetros iniciais utilizando uma semente aleatória, a fim de garantir reprodutibilidade e comparatibilidade, ficando um exercício posterior - O problema era testar novas funções de ativação em exemplos simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi possível aprender mais sobre outras funções de ativação presentes nas redes neurais, aumentando meu conhecimento sobre o tema e a execução de cada etapa do código. Foi interessante analisar os materiais de referência e adaptá-los ao problema atual, melhorando habilidades de criatividade e resolução crítica. Além disso, compreendeu-se a importância do ajuste dos hiperparâmetros, como a taxa de aprendizado, que influenciam diretamente na previsão do modelo e sua eficácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] CASSAR, Daniel. \"ATP-303 NN 4.2 - Notebook MLP.ipynb\". Material de Aula, 2025.\n",
    "\n",
    "[2] Material sobre funções de ativação. 2024. Datacamp. https://www.datacamp.com/pt/tutorial/introduction-to-activation-functions-in-neural-networks\n",
    "\n",
    "[3] Material sobre funções de ativação. 2021. v7labs: https://www.v7labs.com/blog/neural-networks-activation-functions\n",
    "\n",
    "[4] Formas de representar a função tangente hiperbólica. Wikipedia. https://pt.wikipedia.org/wiki/Tangente_hiperbólica\n",
    "\n",
    "[5] Biblioteca Math. https://docs.python.org/3/library/math.html\n",
    "\n",
    "[6] Biblioteca Random. https://docs.python.org/3/library/random.html\n",
    "\n",
    "[7] KARPATHY, Andrej. \"The spelled-out intro to neural networks and backpropagation: building micrograd\". YouTube. https://youtu.be/VMj-3S1tku0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
